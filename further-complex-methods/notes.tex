\documentclass[a4paper]{article}
\input{../../../preamble.tex}

\title{Further Complex Methods}
\date{}
\author{}

\begin{document}
	
\maketitle

\section{Complex Variables}

\begin{defn}
	A \textit{neighbourhood} of a point $z\in \C$ is an open set containing z.
\end{defn}

\begin{defn}
	The extended complex plane $\C_{\infty}$ or $\overline{\C}$ is defined as $\C \cup \{\infty\}$. All directions lead to $\infty$, as in the Riemann sphere. 
\end{defn}

\begin{defn}
	A function $f(z)$ is \textit{differentiable} at z if $f'(z) = \lim_{a\to 0} \frac{f(z+a) - f(z)}{a}$ exists (i.e. is the same for all paths $a \to 0$).
\end{defn}

\begin{defn}
	We say that that $f(z)$ is \textit{analytic/holomorphic/regular} at a point $z$ if it is differentiable in a neighbourhood of $z$. This definition naturally extends to being analytic in a domain $D \subset \C$.
\end{defn}

\begin{prop} Cauchy-Riemann Conditions

For $f(z) = u(z) + i v(z)$, with $u, v \in \R$, f is differentiable at $z$, iff
 \[
\frac{\partial u}{\partial x} = \frac{\partial v}{\partial y}, \quad \frac{\partial v}{\partial x} = - \frac{\partial u}{\partial y}  
\]

Where it exists, this is equivalent to the Wirtinger derivative $\frac{\partial f}{\partial \overline{z}} = 0$, where $\frac{\partial }{\partial \overline{z}} = \frac{\partial }{\partial x} + i \frac{\partial }{\partial y} $ 

\end{prop}

\begin{thm} Cauchy s Theorem
	
	If $f(z)$ is analytic within and on a closed contour $C$ then $\oint_C f(z) = 0$.
	Note that the interior is simply connected.

\end{thm}

\begin{thm} Cauchy s Integral Formula
	
	For $z_0 \in \intr C $, 
	\[
		f(z_0) = \frac{1}{2\pi i} \oint_C \frac{f(z)}{z-z_0} dz
	\]

	Consequently, 
	\[
		f^{(n)}(z_0) = \frac{n!}{2\pi i} \oint_C \frac{f(z)}{(z-z_0)^{n-1}} dz
	,\]
	
	implying that an analytic function is infinitely differentiable. 
	Here, all path integrals are taken anti-clockwise. 
\end{thm}

\begin{defn}
	A function $f(z)$ is \textit{entire} if it is analytic on $\C$ (not  $\C_{\infty}$ ).
\end{defn}

\begin{thm} Liouville's Theorem

	If $f$ is entire and bounded on $\C_{\infty}$, then it is constant. 
	
\end{thm}

\begin{proof}
	Consider a circular disk of radius $R$, i.e. $D = \{z: |z-z_0| < R\}$, and pick $M$ s.t. $|f(z)| < M$.

	Then \[
		|f^{(n)}(z_0)| \le \frac{n!}{2\pi} \oint_{C} \frac{|f(z)|}{|z-z_0|^{n-1}} dz \le \frac{n!M}{2\pi R^{n+1}} \oint_C |dz| \le \frac{n!M}{R^{n}}
	\]
	As this holds for all $R, z_0$, we must have that $f'$ vanishes identically, and so $f(z) = f(0)$. 
\end{proof}

\subsection{Series expansions}

An analytic function has a convergent Taylor expansion about any point within its domain of analyticity:
\[
	f(z) = \sum_{n=1}^{\infty} \frac{f^{(n)}(z_0)}{n!} (z-z_0)^{n}

\] 

We can also consider Laurent series for functions $f(z)$ with an isolated singularity about some point $z_0$, but analytic in a neighbourhood of $z_0$.

\[
	f(z) = \sum_{n=-\infty}^{\infty} C_n (z-z_0)^n, \quad C_n = \frac{1}{2\pi i} \oint \frac{f(z)}{(z-z_0)^{n+1}} dz
\] 

We can classify the singularity as follows:

\[
	f(z) = \sum_{n=0}^{\infty} C_n (z-z_0)^{n} + \sum_{n=1}^{N} C_{-n} (z-z_0)^{-n}
\]

Then $z_0$ is:

\begin{enumerate}
	\item A regular point (or 0) if $C_{-n} = 0 \, \forall n\ge 1$.\\
	\item A simple pole if $N=1$ \\
	\item A  pole of order  $N$ if $N>1$ (here we can write $f = \frac{g}{(z-z_0)^{N}}$, $g$ analytic)\\
	\item And essential singularity if $N \to \infty$.
\end{enumerate}

The coefficient $C_{-1}$ in our Laurent series is called the \textit{residue} of $f$ at $z_0$.

For a pole of order $N$, $C_{-1} = \frac{1}{(N-1)!} \frac{d^{N-1}}{dz^{N-1}} [(z-z_0)^{N} f(z)]\Bigr\rvert_{z=z_0}$

\begin{thm} Residue Theorem
	
	If $f$ is analytic in a simply-connected domain, except at a finite number of isolated singularities $z_1, \ldots, z_n$, then

\[
	\oint f(z) dz = 2\pi i \sum_{k=1}^{n} \res(f(z); z_k)
\]

\end{thm}

\begin{lemma} The Identation Lemma

	Consider a simple pole at $z_0$.

\begin{figure}[ht]
    \centering
    \incfig{indentation}
    \caption{}
    \label{indentation}
\end{figure}
	
Then \[
	\lim_{\epsilon \to 0} \int_{C_{\epsilon}} f(z) dz = i(\beta - \alpha) \res(f; z_0)
,\] where on $C_{\epsilon}$, $z = z_0 + \epsilon e^{i \theta}$, $\alpha \le \theta \le \beta$. 
\end{lemma}

\begin{proof}
	
Consider the Laurent expansion of $f$ about $z_0$.
\[
	f(z) = \frac{\res(f; z_0)}{z-z_0} + g(z)
,\] where $g$ is analytic in the region $|z-z_0| < r$, $r>0$.

By continuity of  $g$ at $z_0$, we can choose $r$ small enough such that $g$ is bounded by some $M\in \R$. On $0 < \epsilon < r$, we have 
\begin{align*}
	\int_{C_{\epsilon}} f(z) dz &= \res(f;z_0) \int_{C_{\epsilon}} \frac{dz}{z-z_0} + \int_{C_{\epsilon}} g(z) dz \\
	&= i \res(f;z_0) \int_{\alpha}^{\beta} i d\theta + \int_{C_{\epsilon}} g(z) dz  \\
	&= i(\beta-\alpha) \res(f;z_0) \text{ in the limit } \epsilon \to 0, \text{ as $g$ is bounded. }
\end{align*}

\end{proof}

\subsection{Functions defined by integrals}

Consider $F(z) = \int_{C} f(z,t) dt$, where $C$ is some contour in $\C$ (not necessarily closed). We wish to find out when such an $F$ is defined and analytic.

\subsubsection*{Conditions on analyticity}

We need to check that:
\begin{enumerate}
	\item The integrand is continuous in $t$ and $z$.
	\item The integral converges uniformly in each subset of its domain.
	\item The integrand is analytic in $z$ for each value of $t$.
\end{enumerate}
This second condition will not be treated rigorously.

\begin{eg}
	\[
		F(z) = \int_{-\infty}^{\infty} e^{-zt^2} dt \left( = \sqrt{\frac{\pi}{z}}  \right) 
	\]

	The integral converges for $\Re(z) > 0$, and diverges for $\Re(z) <0$. If  $z \in i\R$, then the integrand $e^{-iyt}$ oscillates increasingly rapidly, and $F(z)$ is not absolutely convergent, but conditionally convergent, i.e.
	\[
	\lim_{l\to \infty} \int_{-l}^{l} |e^{-iyt^2}|dt \to  \infty
	,\] but
	\[
		\lim_{l\to \infty} \int_{-l}^{l} e^{-iyt^2} dt \text{ is finite.}
	\] 

	Conditions 1&3 hold. It can be shown that 2 also holds. 
\end{eg}

\begin{eg}
	\[
		F(z) = \int_{0}^{\infty} \frac{u^{z-1}}{u+1} du
	\]

	\begin{enumerate}
		\item Existence: Potential problems when $u=0,\infty$. The integrand is otherwise well behaved (except for $-1$, which is outside the range of integration). There are no problematic values of $z$, as  $u^{z-1} = e^{(z-1)\log u}$.

		At $u=0$, we have  $\int_{0} u^{z-1} du = \frac{u^{z}}{z} \big\rvert_{0}$
		\[
		|u^{z}| = |e^{z\log u}| = e^{x\log u}
		\]
		So to have this converge (to  $0$ ), we require $\Re(z) >  0$. 

		At $u = \infty$, $u+1 \approx u$, and  $\int ^{\infty} u^{z-2} = \frac{u^{z-1}}{z-1}$
		\[
			|u^{z-1}| = e^{(x-1)\log u}
		,\] so we require $\Re(z) < 1$.

		If $\Re(z) = 0,1$, we also do not have convergence.
		Thus  $F(z)$ is defined for $0<\Re(z) < 1$.

	\item Analyticity: Conditions 1&3 are clearly satisfied in $0<\Re (z) < 1$. 2 probably is.
	\end{enumerate}

	So $F(z)$ is analytic for $0 < \Re(z) < 1$.

	We can evaluate it using a circular keyhole contour. On $C_R$,  $t = Re^{i\theta}$, on $C_{+}$, $ t = u, \epsilon < u < R $, on $C_{-}$, $t = ue^{2\pi i}, R > u > \epsilon$, and on $C_{\epsilon}$, $t = \epsilon e^{i\theta}$.
	
	So, $\int_{C_{-}} \frac{t^{z-1}}{t+1} du = -(e^{2\pi i})^{z-1} F(z)$.

	As $0 < \Re(z) < 1$, $\lim_{R\to \infty} R^{1-z} = $, and so our  $C_R$ integral goes to $0$.
	Similarly, so too does our  $C_{\epsilon}$ integral.

	Therefore,

	\begin{align*}
		(1-e^{2\pi i(z-1)})F(z) &= 2\pi i \times e^{-i \pi (z-1)} \\
		\implies F(z) &=  \frac{\pi}{\sin \pi z }
	\end{align*} 

	We will see later that $F(z) = \Gamma(z) \Gamma(1-z)$.
\end{eg}

\subsection{Analytic Continuation}

We have that  $F(z) = \int_{-\infty}^{\infty} e^{-zt^2}dt$ is analytic for $\Re(z) > 0.$ We would like to know if it is possible to extend its domain of analyticity, and whether such an extension is unique.

\begin{thm} Identity Theorem
	
	Let $g_1, g_2$ be analytic functions in a connected, non-empty, open set $D \subset \C$ with $g_1 = g_2$ in a non-empty open subset $\tilde{D} \subset D$. Then $g_1 = g_2$ on $D$.

\end{thm}

\begin{proof} (sketch)

Expand $g_1 - g_2$ as a Taylor expansion about $z_0 \in \tilde{D}$. Then the series holds in all of $D$, and is identically $0$ in $\tilde{D}$. Therefore  $g_1-g_2 = 0$ on $D$. 
\end{proof}
We can extend this proof by replacing our set $\tilde{D}$ by a contour $\gamma \subset D$.

\begin{defn} Analytic Continuation

	Let $D_1, D_2$ be open sets with $D_1 \cap D_2 \neq \emptyset$. Let $f_1$ and $f_2$ be analytic on $D_1$ and $D_2$ respectively, with $f_1 = f_2$ on $D_1 \cap D_2$. Then we say that $f_2$ is the \textit{analytic continuation} of $f_1$ from $D_1$ to $D_2$.
\end{defn}

\begin{prop}
	Our analytic continuation $f_2$ is unique.
\end{prop}

\begin{proof}
	Suppose there exists  $\tilde{f}_2 \neq f_2$ which provides such an analytic continuation with $\tilde{f}_2 = f_1$ on $D_1 \cap D_2$. Define
	\begin{align*}
		g_1 &= \begin{cases}
		f_1 \text{ on } D_1 \\
		f_2 \text{ on } D_2
	\end{cases} \\
	g_2 &= \begin{cases}
		f_1 \text{ on } D_1 \\
		\tilde{f}_2 \text{ on } D_2
	\end{cases}
\end{align*}

Then by the identity theorem, $g_1 = g_2$, and so $f_2 = \tilde{f}_2$ and our analytic continuation is unique. 
\end{proof}

 \begin{prop} Monodromy Theorem

	 If we have open sets $D_1$, $D_3$ with $D_1 \cap D_3 = \emptyset$, with a function $f_1$ defined on $D_1$. A unique analytic continuation of this to $D_3$ is possible iff we can analytically continue $f_1$ through all domains $D_2$ connecting $D_1$ and $D_3$ with $D_1 \cap D_2, D_2 \cap D_3 \neq \emptyset$.	 
\end{prop}

\begin{proof}
	Left as an exercise to a different reader.
\end{proof}

\subsubsection*{Methods of Analytic Expansion}

\begin{enumerate}
	\item Taylor expansion

		If we pick $z_0$ near the boundary of our domain $D$, we can extend  $f_1$ to a disk $|z-z_0| < r$ for some radius of convergence $r$.

	\begin{eg} Note that
		\begin{align*}
			f(z) &= \frac{1}{1-z} \\
			&= \frac{1}{1-z_0} \frac{1}{1-\frac{z-z_0}{1-z_0}} \\
			&= \frac{1}{1-z_0} \sum_{n=0}^{\infty} \left(\frac{z-z_0}{1-z_0}\right)^{n}\\
		,\end{align*} which converges for $|z-z_0| < |1-z_0|$.

		Now, let $f_1 = \sum_{n=0}^{\infty} z^{n}$. It is analytic for $|z|<1$. Let $f_2 = \sum_{n=0}^{\infty} \frac{(z-\frac{i}{2})^{n}}{(1-\frac{i}{2})^{n+1}}$, analytic on $|z-\frac{i}{2}| < \frac{\sqrt{5} }{2} $. We have that  $f_1 = f_2$ on the intersection of the disks, and hence by the identity theorem, $f_2$ is the analytic continuation of $f_1$. This can be continued as a chain of disks covering $\C \setminus \{1\} $, to obtain the function $\frac{1}{1-z}$, which has a simple pole at $z=1$. 	
	\end{eg}
	This is known as meromorphic continuation (analytic continuation excluding singularities).
	However, such extensions are not always possible.

	\begin{eg}
		Let $f(z) = \sum_{n=0}^{\infty} z^{2^{n}}$ is convergent in $|z|<1$ by ratio test, but its singularities are dense, and analytic continuation is not possible. We call $|z|=1$ a \textit{natural barrier}.
	\end{eg}
	\item Contour deformation
		\begin{eg}
		Let $F(z) = \int_{-\infty}^{\infty} \frac{e^{it}}{t-z} dt$ for $\Im z > 0$.

		We want to continue $F(z)$ to the lower half-plane, but obviously it is not analytic for  $\Im z = 0$. So, we might think to re-define $F$ for $\Im z \neq 0$. We shall see shortly why this does not work.

		Pick  $z_1$ with $\Im z_1 <0$. We wish to continue $F$ into a neighbourhood of $z_1$ by deforming our path of integration. 

\begin{figure}[ht]
    \centering
    \incfig{deformed-path}
\end{figure}
		Define \[
			F_1(z) = \int_{C} \frac{e^{it}}{t-z}
		\] 

		Then $F_1$ is analytic for all $z$ above $z_1$. For $\Im z > 0$, we can see by deforming our new path to the real axis, that $F_1 = F$. Therefore, $F_1$ is the analytic continuation of $F$ into $\Im z < 0$.

		Now, instead consider $G(z) = \int_{-\infty}^{\infty} \frac{e^{it}}{t-z} dt$ for $\Im z \neq 0$. So if  $\Im z > 0$, then $G(z) = F(z)$ by definition.

		If $\Im z < 0$, then consider closing the contour with our path $C$ above. We find \[
			F_1(z) - G(z) = 2\pi i e^{iz} 
		\]
		So for $\Im z > 0$, we have that $F = F_1 = G$, and for $\Im z < 0$ we have  $F_1 = G- 2\pi i e^{iz}$. 

		Hence $G$ jumps by $2\pi i e^{iz}$ as it crosses the real axis.
		\end{eg}
\end{enumerate}

\subsection{Cauchy Principal Value}

\begin{idea}
	Can we say that \[
	\int_{-1}^{2} \frac{dx}{x} = \log 2 - \log|-1| = \log 2
	?\] 
\end{idea}

\begin{defn}
	If $f(x)$ is badly-behaved at $x=c$ and $a<c<b$, we can define the \textit{Cauchy Principal Value} integral by
	\[
		\mathcal{P} \int_a^{b} f(x) dx := \lim_{\epsilon \to 0} \int_{a}^{c-\epsilon} f(x) dx + \int_{c + \epsilon}^{b} f(x) dx
	\]
	when the limit exists of course.
\end{defn}

\begin{eg}
	Let $I = \mathcal{P} \int_{-\infty}^{\infty} \frac{f(x)}{x} dx$, where $f$ is analytic  in the upper half-plane and real axis, and $f(x) \to 0$ at infinity.

	Closing in the UHP, our $C_R$ contribution vanishes in the limit $R\to \infty$, and our $C_{\epsilon}$ term contributes $-i\pi f(0)$, where by analyticity of $f$, our residue at the origin is $f(0)$.
	Hence
	\[
		\mathcal{P} \int_{-\infty}^{\infty} \frac{f(x)}{x} = i\pi f(0)
	\] 
\end{eg}

\begin{eg}
	Let $I = \int_{-\infty}^{\infty} \frac{1-\cos x}{x^2}$. Our integrand has a removable singularity at $x=0$. We can show using standard methods that  $I = \pi$.

	Alternatively, $I = \Re \mathcal{P} \int_{-\infty}^{\infty} \frac{1-e^{ix}}{x^2}$. Closing this in an arch, we get by indentation lemma that
	\[
		\mathcal{P}\int_{-\infty}^{\infty} \frac{1-e^{ix}}{x} -i\pi (-i) = 0
	,\]
	So $I=\pi$, and $\mathcal{P} \int_{-\infty}^{\infty} \frac{\sin x}{x^2} = 0$.
\end{eg}

\subsection*{Hilbert Transforms}

\begin{defn}
	The Hilbert transform of $f(x)$ is defined by
	\[
		\mathcal{H}(f)(y) = \frac{1}{\pi} \mathcal{P} \int_{-\infty}^{\infty} \frac{f(x) dx}{x-y}
	\] 
\end{defn}

\begin{remark}
	Observe that $\mathcal{H}$ is a linear functional.
\end{remark}

We shall assume that $f$ has a Fourier decomposition, so we only need to consider the Hilbert transform of $e^{i\omega x}$, and then use linearity of the transform. We will show that 
\[
	\mathcal{H}(e^{i\omega x})(y) = \begin{cases}
		ie^{i\omega y}, \; \omega > 0 \\
		-ie^{i\omega y}, \; \omega < 0
	\end{cases} = i \sgn(\omega) e^{i\omega y}
\] 

Integrating in an arch shaped contour about $y$, we get
\begin{align*}
	\mathcal{P} \int_{-\infty}^{\infty} \frac{e^{i\omega x}}{x-y} dx + \underbrace{\int_{C_R}}_{\to 0} + \underbrace{\int_{C_\epsilon}}_{= -i\pi e^{i\omega y}} &= 0
\end{align*}

And flipping our arch for $\omega < 0$, we get a negative sign from the indentation lemma, so the result indeed holds.

\begin{remark}
	From this it follows that $\mathcal{H}^2(e^{i\omega x}) = -e^{i\omega x}$, so $\mathcal{H}$ is "anti-self-inverse" here.

	More (but not completely of course)  generally, if $g(y) = \mathcal{H}(f)(y)$, then
	\[
		f(x) = \frac{1}{\pi} \mathcal{P} \int_{-\infty}^{\infty} -\frac{g(y)}{y-x}
	\] 
\end{remark}

\subsection*{Kramers-Kronig Relations}

Let $f=u+iv$ be analytic in $\Im z >0$, with $f\to 0$ as $|z|\to \infty$. Let $x' = z' \in \R$, and consider C as follows:
\begin{figure}[ht]
    \centering
    \incfig{contour}
\end{figure}

Then by indentation lemma, \[
	\int_{C} \frac{f(z)}{z-z'} dz = \mathcal{P} \int_{-\infty}^{oo} \frac{f(x) dx}{x-x'} - i\pif(x) = 0 \tag{1}
\]

For $z \in \R$, we can write $f(z) = f(x,y) = f(x,0)$, with $f(x,0) = u(x,0) + iv(x,0)$.

Hence, taking real and imaginary parts of (1), we obtain

\begin{align*}
	\mathcal{P} \int_{-\infty}^{\infty} \frac{u(x) dx}{x-x'} &= -\pi v(x') \\
	\mathcal{P} \int_{-\infty}^{\infty} \frac{v(x)dx}{x-x'} &= \pi u(x')
\end{align*}

Or
\begin{align*}
	\mathcal{H} u(x') &= -v(x') \\
	\mathcal{H} v(x') &= u(x')
\end{align*}

These are known as the Kramers-Kronig relations, relating the real and imaginary parts of functions analytic in the upper half plane.

\begin{eg} The Laplace equation in the upper half plane

	Let $u(x,y)$ be a harmonic function in $\Im z>0$. Recall that for $\frac{\partial }{\partial z}  = \frac{1}{2} \left( \frac{\partial }{\partial x} - i \frac{\partial }{\partial y}  \right)$, we have
	\[
	4 4 4 4 \frac{\partial ^2 u}{\partial z \partial \overline{z}}u = \frac{\partial^2 u}{\partial x^2} + \frac{\partial^2u }{\partial y^2}  = 0
	\]

	Suppose $u\to 0$ for large $|x|, y$.

	Consider  $F(z) = \frac{\partial u}{\partial z} $. $\frac{\partial F}{\partial \overline{z}} $ implies analyticity for $\Im z > 0$, and so
	\begin{align*}
		u_x (x,0) &= -\mathcal{H} u_y (x,0) \\
		u_y (x,0) &= \mathcal{H} u_x (x,0)
	\end{align*}
	 
\end{eg}

\subsection{Multivalued Functions}

\begin{defn}
	A multivalued function $f(z)$ admits more than one value for given $z$.
\end{defn}

\begin{defn}
	A point $z=a$ is a branch point of the multivalued function $f(z)$ if $f$ is discontinuous upon traversing in a small circle about $z=a$ i.e.  $f(a+re^{2\pi i}) \neq f(a+r)$.
\end{defn}

\begin{eg}
	$f(z) = (1-z^2)^{\frac{1}{2}} = (1-z)^{\frac{1}{2}(1+z)^{\frac{1}{2}}}$ has branch points at $z=\pm 1$.

	For $z=1$, consider $z=1 + \epsilon e^{i\theta}, 0<\epsilon \ll 1$.
	\[
		f(z) = (-\epsilon e^{i\theta})^{\frac{1}{2}}(2+\epsilon e^{i\theta})^{\frac{1}{2}} \approx \pm i \sqrt{2\epsilon} e^{i\frac{\theta}{2}}
	\]
	And it is easily seen that this is a branch point.

	Note that $\infty$ is not a branch point (consider $t = \frac{1}{z}$).

\end{eg}

\vspace{1em}

We seek to express a multivalued function in terms of a singlevalued function. This is achieved by restricting the region in $\C$ to cut in such a way that the resulting function is singlevalued and continuous.

\begin{defn}
	A continuous singlevalued function obtained in this way is called a \textit{branch} of the multivalued function.
\end{defn}

\subsection*{Integrating using a branch cut}

We seek to evaluate \[
	I = \int_{-1}^{1} (1-x^2)^{\frac{1}{2}} dx
\] by contour integration.

We choose $f(z)$ to be the branch of $(1-z^2)^{\frac{1}{2}}$ with $f(0^{+}) = 1$, given in local polars by \[
	f(z) = |1-z^2|^{\frac{1}{2}} e^{\frac{i}{2}\left(\phi_1 + \phi_2 - \frac{\pi}{2}  \right) }
\]

You then do some boring stuff, and get the answer to be  $2\pi$ or something.

\subsection*{The arcsin function defined as an integral}

Let \[
	\Arcsin z = \int_{0}^{2\pi} \frac{dt}{(1-t^2)^{\frac{1}{2}}}
,\] where $\sqrt{1-t^2} $ is defined by a branch cut between $-1$ and $1$ as before, such that it takes value  $1$ at $0^{+}$, and where $0 \le  \arg z < \pi$

See siklos' notes.

\section{Special Functions}

\subsection{The Gamma Function}

We are motivated by finding a smooth curve that interpolates the points $f(n) = n!, n \in \N$. We find such a magical function to be given by $f(x) = \Gamma(x+1)$! We now seek to generalize this in integral form to $\C$.

Let  $I(z) = \int_{0}^{\infty} t^{z-1} e^{-t} dt$ (Euler's Integral), which converges and is analytic for $\Re z >0$. 

Now, 
\begin{align*}
	I(z+1) = \int_{0}^{\infty} t^{z}e^{-t} dt &= \left[ -t^{z}e^{-t} \right]_{0}^{\infty} + \int_0^{\infty} zt^{z-1}e^{-t} dt \\
	&= \I(z)
\end{align*}

Also, $I(1) = 1$. Hence  \[
	I(n+1) = n!I(1) = n!, \; n\in \N
\]

So our idea is to define
\[
	\Gamma(z) = \begin{cases}
		I(z), \qquad \Re z >0 \\
		\text{Analytic continuation elsewhere}
	\end{cases}
\] 

Now, we can see that  \[
	I(z) = \frac{I(z+1)}{z}
\] is analytic for $\Re (z+1) > 0$, and  $z\neq 0$. As such, we can iteratively extend this to
\[
	I(z) = \frac{I(z+n+1)}{z(z-1)\ldots(z+n)}
,\] which is analytic for $\Re z > -(n+1)$, $z\neq 0, -1, \ldots, -n$.

Hence we can meromorphically continue $\Gamma(z)$ to $\C\setminus \{-n: n\in \N\} $, with simple poles at the negative integers. It is easily seen that $\res(\Gamma(z); -n) = (-1)^{n} \Gamma(1) \frac{1}{n!} = \frac{(-1)^{n}}{n!} $

\subsubsection*{Some alternative definitions and formulae}

\begin{prop} Euler Product Formula
	\[
		\Gamma(z) = \lim_{n\to \infty} \frac{n! n^{z}}{z(z+1)\ldots(z+n)}, \qquad \forall z \in \C \setminus (-\N)
	\] 
\end{prop}

\begin{proof}
	Firstly, we consider $\Re z > 0$. Recall that  $e^{-t} = \lim_{n\to \infty} \left(1-\frac{t}{n}\right)^{n}$.

	So,
	\begin{align*}
		\Gamma(z) &= \lim_{n\to \infty} \int_{0}^{n} \left(1-\frac{t}{n}\right)^{n} t^{z-1} dt \\
		&= \lim_{n\to \infty} n^{z} \left[ \frac{(1-\tau)^{n}\tau^{z}}{z}  \right]_{0}^{1} - \frac{n^{\tau}}{z} (-n) \int_{0}^{1} (1-\tau)^{n-1} \tau^{z} d\tau  \quad (\tau = \frac{t}{n}) \\
		&= \lim_{n\to \infty} 0 + (-1)^{n}n^{z} n! \int_{0}^{1} \frac{\tau^{z+n-1}}{z(z+1)\ldots(z+n-1)} \\
		&= \lim_{n\to \infty} \frac{n! n^{z}}{z(z-1)\ldots(z+n)}
	\end{align*} 
	
	For $\Re z \le 0$, it is clear to see that our analytic continuation by $\Gamma(z) = \frac{\Gamma(z+1)}{z}$ continues the product formula, and is indeed analytic. 
\end{proof}

\begin{prop} Gauss Product Formula
	\[
		\Gamma(z) = \frac{1}{z} \prod_{n=1}^{\infty} \frac{\left(1+\frac{1}{n}\right)^{z}}{1+\frac{z}{n}}
	\] 
\end{prop}

\begin{proof}
	By the Euler product formula, we can write
	\begin{align*}
		\Gamma(z) &= \lim_{n\to \infty} \frac{1}{z} \frac{n^{z}}{\frac{z+1}{1}\frac{z+2}{2}\ldots\frac{z+n}{n}} \\
		&= \frac{1}{z} \lim_{n\to \infty} \frac{\left\frac{n+1}{n}\right)^{z}\left( \frac{n}{n-1}\right)^{z} \ldots \left \frac{2}{1} \right)^{z} \left( \frac{n}{n+1}\right)^{z} }{(1+z)(1+\frac{z}{2})\ldots(1+\frac{z}{n})} \\
	\end{align*}
	As $\left( \frac{n}{n+1} \right)^{z} \to 1 \text{ as } n\to \infty$, we obtain the required expression.
\end{proof}

\begin{prop} The Weierstrass Canonical Product
	\[
		\frac{1}{\Gamma(z)} = z e^{\gamma z} \prod_{k=1}^{\infty} \left( 1 + \frac{z}{k} \right) e^{-\frac{z}{k}}
	,\] where $\gamma = \lim_{n\to \infty} 1 + \frac{1}{2} + \ldots + \frac{1}{n} - \log n \approx 0.577$ is the Euler-Mascheroni constant.
\end{prop}

\begin{proof}
	Using Euler's product formula,
	\begin{align*}
		\frac{1}{\Gamma(z) } &= z \lim_{n\to \infty} \frac{(1+z)(2+z)\ldots(n+z)}{n! n^{z}} \\
		&= z \lim_{n\to \infty} e^{-z \log n} \left(1+z\right)\left(1+\frac{z}{2}\right)\ldots\left(1+\frac{z}{n}\right) \\
		&= z \lim_{n\to \infty} e^{-z\left( \log n - (1 + \frac{1}{2} + \ldots + \frac{1}{n}) \right) }e^{-z\left( 1+\frac{1}{2} + \ldots + \frac{1}{n} \right) } \left(1+z\right)\ldots\left(1+\frac{z}{n}\right)  \\
		&= z e^{\gamma z} \prod_{k=1}^{\infty} \left( 1+ \frac{z}{k} \right) e^{-\frac{z}{k}}
	\end{align*} 
\end{proof}

\begin{prop} Reflection Formula
	
	\[
		\Gamma(z)\Gamma(1-z) = \pi \csc (\pi z), \quad z \not\in \Z
	\]
\end{prop}

\begin{proof}
	We first consider the case  $\Re z \in (0,1)$ so that we can write $\Gamma(z)$ and $\Gamma(1-z)$ can be written in integral form. Using substitutions $t = r \sin^2\theta$, $s = r \cos^2\theta$, we have 
	\begin{align*}
		\Gamma(z) \Gamma(1-z) &= \int_0^{\infty} e^{-t} t^{z-1} dt \int_0^{\infty} e^{-s} s^{-z} ds \\
				      &= 2 \int_0^{\frac{\pi}{2}} (\tan \theta )^{2z-1} d\theta \\
				      &= \int_{0}^{\infty} \frac{u^{z-1}}{u+1} du \\
				      &= \frac{\pi}{\sin (\pi z)}
	\end{align*}
	Where we used the substitution $\tan \theta = u^{\frac{1}{2}}$, and calculated the last integral earlier.

	Now, $\Gamma(z)$, $\Gamma(1-z)$ and $\pi (\csc \pi z)$ are analytic for all $ z$ except integer points, and they are equal for $\Re z \in (0,1)$, and so the result holds by analytic continuation.
\end{proof}

\begin{corollary}
	$\Gamma(\frac{1}{2}) = \sqrt{\pi} $
\end{corollary}

\subsection{Hankel Representation of $\Gamma(z)$ }

\begin{prop} Hankel Representation
	
	For $z \not\in \Z\setminus\N$,
	\[
		\Gamma(z) = \frac{1}{2i \sin(\pi z)} \int_{-\infty}^{0^+} e^{t}t^{z-1} dt
	,\] where $-\pi \le \arg t \le  \pi$, and the path is called the \textit{Hankel contour}. Note that the function is analytic in both $z$ and $t$.
\end{prop}

\subsubsection*{Well-Definedness of Hankel Integral}

Note that for $\Re z > 0$, the Hankel representation is equal to the Gaussian integral $I(z)$ from earlier. To see this, we collapse the Hankel contour onto the branch cut, and define for $\Re z > 0$,
\[
	J(x) = \int_{-\infty}^{0^{+}} e^{t}t^{z-1} dt = \int_{\gamma_1} + \int_{\gamma_2} + \int_{\gamma_{\epsilon}}
,\] defining contours
\[
\gamma_1: t = xe^{i\pi}, \infty > x > \epsilon, \quad \gamma_2: t = x e^{i\pi}, \epsilon < x < \infty, \quad \gamma_{\epsilon}: t = \epsilon e^{i\theta}, -\pi < \theta < \pi
\] 

Note that we have
\begin{align*}
	\int_{\gamma_1} &\to (e^{-\pi})^{z} \int_{-\infty}^{0} e^{-x}x^{z-1} dx \\
	\int_{\gamma_2} &\to (e^{i\pi})^{z} \int_0^{\infty} e^{-x} x^{z-1} dx \\
	\int_{\gamma_{\epsilon}} &\to 0 \text{ as } \Re z > 0 \text{ and } \epsilon \to 0
\end{align*}

so we have
\[
	J(z) = 2i \sin(\pi \) I(z)
\]

Hence the claim is proved by analytic continuation.

Note that for $z \in \N$, the zeroes of $\sin (\pi z)$ are cancelled by the integral, and $t=0$ is not a branch point, so there are no singularities in the Hankel contour. This suggests that $J(z) = 0$.

\subsubsection*{Residues of $\Gamma(z)$ in Hankel Representation}

In this case with $z \in \N$, we can choose a Hankel contour to be a unit circle enclosing the origin anticlockwise. Now,
\[
	J(-m) = \int_{|t| = 1} e^{t}t^{-(m+1)} dt = 2\pi i \res\left(e^{t} t^{-(m+1)}; 0  \right) 
\]
Using Taylor expansion,
\[
	e^{t}t^{-(m+1)} = \sum_{n=0}^{\infty} \frac{t^{n-m-1}}{n!}
,\]
and the residue is then the coefficient of $t^{-1}$, $m!$.
So  $J(-m) = \frac{2\pi i}{m!}$.

Thus the residue of $\Gamma(z)$ at $z = -m$ is $\lim_{z\to -m} \frac{z+m}{2i \sin \pi z} J(z) = \frac{2\pi i}{m!} \lim_{z\to -m} \frac{z+m}{2i \sin \pi z} = \frac{(-1)^{m}}{m!}$ by l'H\^{o}pital as expected. 

\vspace{1em}

We now seek to answer whether the Gamma function is the unique analytic interpolation problem of the factorial.

\begin{thm}
	Wielondt's Theorem

	If $F(z)$ satisfies:
	\begin{enumerate}
		\item $F(z)$ is analytic for $\Re z > 0$ \\
		\item  $F(z+1) = zF(z)$ \\
		\item  $F(z)$ is bounded in $1 \le  \Re z \le 2$ \\
		\item $F(1) = 1$ 
	\end{enumerate}
	then $F(z) = \Gamma(z)$.
\end{thm}

\begin{lemma}
	Define the difference function
	\[
		f(z) := F(z) - \Gamma(z)
	\]

	Then $f(z)$ is entire.
\end{lemma}

\begin{proof}
	Properties 1 and 2 imply that $F(z)$ can be meromorphically continued into $\C \setminus\left( -\N \right) $, 
	\[
		F(z) = \frac{F(z+n)}{z(z+1)\ldots(z+n-1}
	\]

	By property 4, $\res\left( F(z); -n \right) = \frac{F(1) (-1)^{n}}{n!}$, which is the same as the gamma function. Hence $f(z)$ has only removable poles, and is in fact entire.
\end{proof}

\begin{lemma}
	$f(z)$ is bounded in the strip $0 \le \Re z \le  1$.
\end{lemma}

\begin{proof}
	We first show that $f(z)$ is bounded on $ 1 \le  \Re z \le 2$. It suffices to check that $\Gamma(z)$ is.

	\begin{align*}
		|\Gamma(z)| &= \left| \int_{0}^{\infty} e^{-t}t^{z-1} dt \right| \\
		&\le \int_{0}^{\infty} \left| e^{-t} t^{x+ iy -1} \right| dt \\
		&= \int_{0}^{\infty} e^{-t} t^{x-1} dt \\
		&\le  \int_{0}^{\infty} e^{-t} t^{2-1} dt \\
		&= 1
	\end{align*}

	We examine our last inequality more closely:

	Define $I(x) = \int_{0}^{\infty} e^{-t} t^{x-1} dt$
	$I(1) = I(2) = 1$.  $\frac{d^2 I}{dx^2} > 0 $, so $I(x) $ is convex in $[1,2]$, and the inequality indeed holds.

	Now, for $0\le \Re z \le 1$, we can write $f(z) = \frac{f(z+1)}{z}$. As f is bounded on $1 \le  \Re z \le 2$, we conclude that it is also bounded on $0 \le \Re z \le 1$, noting that the pole is removable at the origin.
\end{proof}

We now prove the original theorem.

\begin{proof} (2.6)

	Let $S(z) = f(z)f(1-z)$. $S(z)$ is entire by lemma 2.7, and is bounded in $0 \le  \Re z \le 1$ by lemma 2.8. Indeed, both $f(z)$ and $f(1-z)$ have the same range in this domain by symmetry.

	Now, $S(z+1) = f(z+1)f(-z) = zf(z) (-z)^{-1} f(1-z) = -S(z)$. Thus $S(z)$ is bounded in $1 \le  \Re z \le  2$.

	Also, $S(z+2) = S(z)$, so $S(z)$ is periodic with period 2, and so is bounded in $\C$. Hence by Liouville's theorem, we must have that $S(z) = S(1) = f(1)f(0) = \left(F(1) - \Gamma(1)\right) f(0) = 0$. Then  $f(z)f(1-z) = 0$ for all $z$. Hence  $f(z) \equiv 0$, and $F(z) \equiv \Gamma(z)$.
	
\end{proof}

\subsection{The Beta Function}

\begin{defn}
	\[
		B(p,q) := \int_0^{1} t^{p-1}(1-t)^{q-1} dt, \quad \Re p, \Re q > 0
	,\]
	and is analytically continued in $p$ and $q$.
\end{defn}

Setting $t = \sin^2\theta$, it is easily shown (on the example sheet) that
\[
	B(p,q) = 2 \int_0^{\frac{\pi}{2}} \sin^{2p-1} \cos^{2q-1} \theta d\theta
\]

\begin{prop}
	\begin{enumerate}
		\item $B(p,q) = B(q,p)$ \\
		\item  $B(1,q) = \frac{1}{q}$ \\
		\item $B(p,z+1) = \frac{z}{p+z} B(p, z)$
	\end{enumerate}
\end{prop}
\begin{proof}
	(1) and (2) are trivial.
	For (3): 
	\begin{align*}
		B(p,z+1) &= \int_0^{1} t^{p-1} (1-t)^{z-1} (1-t) dt \\
			 &= B(p,z) - B(p+1, z) \\
			 &= B(p,q) - \frac{p}{z} B(p, z+1) \text{ upon integrating by parts.}\\
	\end{align*}
\end{proof}

This last identity gives us an analytic continuation of the Beta function into $\Re z > -1$, just as we constructed for the Gamma function.

As our continuation is from $B(p,z) = \frac{p+z}{z} B(p, z+1)$, it is easy to see that much like the Gamma function, for fixed $p$ there are simple poles at $z \in (-\Z)$.

\begin{prop}
	\begin{enumerate}
		\item[4.] $B(p,q) = \frac{\Gamma(p)\Gamma(q)}{\Gamma(p+q)}$ 
	\end{enumerate}
\end{prop}

Notice that for $(n,m) \in \N^2$, $B(n,m) = \frac{(n-1)!(m-1)!}{(n+m-1)!}$ 

\begin{proof}
	 \begin{align*}
		 \Gamma(p)\Gamma(q) &= \int_0^{\infty} e^{-s} s^{p-1} ds \int_0^{\infty} e^{-t} t^{q-1} \\
				    &= \Gamma(p+q) \Beta(p,q), \quad \text{ using } s = r\cos^\theta, t = r \sin^2\theta 
	\end{align*}
\end{proof}

\begin{prop} Pochhammer Representation (non-examinable)

	Let $J(p,q) := \int_{P} f(t) dt$, where  $P$ is Pochhammer's contour

\begin{figure}[H]
    \centering
    \incfig{pochhammer}
\end{figure}

See handout.
\end{prop}

\subsection{The Zeta function}

\begin{defn}
	\[
		\zeta(z) := \sum_{n=1}^{\infty}\frac{1}{n^{z}}, \quad \Re z > 1
	\]
	and is analytically continued wherever possible.
\end{defn}

Euler showed the well known result that $\zeta(2) = \frac{\pi^2}{6}$.

\begin{prop} Integral Representation of $\zeta(z)$

	\[
		\zeta(z) = \frac{1}{\Gamma(z)} \int_{0}^{\infty} \frac{t^{z-1}}{e^{t} - 1} dt, \quad \Re z > 1
	\] 
\end{prop}

\begin{proof}
	Let $t = ns$, for some fixed $n \in \N$, with $s \in \R$.

	Then
	\begin{align*}
		\Gamma(z) = \int_{0}^{\infty} n^{z} s^{z-1} e^{-ns} ds, \quad \Re z > 0 
	\end{align*}
	Hence 
	\begin{align*}
		\zeta(z) \Gamma(z) &= \sum_{n=1}^{\infty} \int_0^{\infty} s^{z-1} e^{-ns} \\
		&= \int_0^{\infty} t^{z-1} \sum_{n=1}^{\infty} e^{-nt} dt \\
		&= \int_0^{\infty} \frac{t^{z-1} e^{-t}}{1 - e^{-t}} dt \\
		&= \int_0^{\infty} \frac{t^{z-1}}{e^t - 1}
	\end{align*}
\end{proof}

\begin{prop} Hankel Representation 

	\[
		\zeta(z) = \frac{\Gamma(1-z)}{2\pi i} \int_{-\infty}^{0^{+}} \frac{t^{z-1}}{e^{-t} - 1} dt
	\] 
\end{prop}

Note that the integrand has simple poles at $2\pi i n$, for $n \in \Z$. We take a branch cut on the negative real axis.

\begin{figure}[H]
    \centering
    \incfig{hankel}
\end{figure}

\begin{proof}
	We show that \[
		\frac{\Gamma(1-z)}{2\pi i} \int_{-\infty}^{0^{+}} \frac{t^{z-1}}{ e^{-t} - 1} dt = \frac{1}{\Gamma(z)} \int_{0}^{\infty} \frac{t^{z-1}}{e^{t} -1} dt
	,\] 
	and show that the LHS gives the analytic continuation of the RHS into $\Re z < 1$.

	On our bottom line, $t = xe^{-i\pi}$, on the circle, $t = \epsilon e^{i\theta}$, and on top $t = xe^{i\pi}$. Treating this just as with the Gamma function,

	 \begin{align*}
		 \int_{-\infty}^{0^+} &= \int_{\gamma_1} + \underbrace{\int_{\gamma_{\epsilon}}}_{\to 0} + \int_{\gamma_2} \\
		 &= \left(e^{i\pi z} - e^{-i \pi z}\right)\int_{0}^{\infty} \frac{x^{z-1}}{e^{x} - 1} dx \\
		 &= 2 i \sin \pi z \Gamma(z) \zeta(z) \text{ by } (2.14)\\ 
	 \end{align*}

	 Then 
	 \begin{align*}
		 \frac{\Gamma(1-z)}{2\pi i} \int_{-\infty}^{0^{+}} \frac{t^{z-1}}{e^{-t} - 1} dt &=  \frac{\Gamma(1-z)}{2\pi i} 2 i \sin \pi z \Gamma(z) \zeta(z)\\ 
		 &= \pi \frac{\csc \pi z}{\pi} \sin \pi z \zeta(z) \text{ by reflection formula}\\
		 &= \zeta(z)
	 \end{align*}
\end{proof}

The integral on the LHS is entire in $z$ and smooth in $t$, and hence provides an analytic continuation of $\zeta(z) $ into $\Re z < 1$.

 \begin{prop}
	The $\zeta$-function extends to a meromorphic continuation into $\C$, with the only singular point being a simple pole at  $z=1$ with residue $1$.
\end{prop}

\begin{proof}
	Notice that $\Gamma(1-z)$ has simple poles at $z = 1,2,3,\ldots$
	But $\zeta(z) $ is analytic for $\Re z > 1$ from its series definition. Hence, $z=1$ is the only singularity of $\zeta$.

	The residue
	\begin{align*}
		\res(\zeta(z); 1) &= \lim_{z\to 1} \frac{(z-1) \Gamma(1-z)}{2\pi i} \int_{-\infty}^{0^{+}} \frac{t^{z-1}}{e^{-t} - 1} dt \\
		&= \lim_{z\to 1} \frac{(z-1)\Gamma(1-z)}{2\pi i} \oint_{|z| = \frac{1}{2}} \frac{dt}{e^{-t} - 1} dt
	\end{align*}

	Note that for $z = -n$, $n \in \N_0$, then $\Gamma(z) = \frac{(-1)^{n}}{n!} \frac{1}{z+n} + \text{ analytic function}$.

	So,
	\begin{align*}
		\lim_{z\to 1} (z-1) \Gamma(1-z) = \lim_{z\to 1} (z-1) \left( \frac{(-1)^{0}}{0!} \frac{1}{1-z} + \text{ analytic function} \right) = -1
	\end{align*}
	Also,
	\[
		\cint_{|z|=\frac{1}{2}} \frac{dt}{e^{-t} - 1} = 2\pi i \cdot  (-1)
	\]

	Hence $\res\left( \zeta(z) ; 1 \right) = 1$. 
\end{proof}

What about the zeroes of $\zeta(z)$? 

\begin{prop}
	Functional Equation for $\zeta(z)$.

	 \[
		 \zeta(z) = 2^{z} \pi^{z-1} \sin\left( \frac{\pi z}{2} \right) \Gamma(1-z) \zeta(1-z)
	 \] for all z.
\end{prop}

\begin{proof}
	We derive this for $\Re z < 0$, and then use analytic continuation.

	We modify the Hankel contour as follows, closing in a rectangle with vertices at \[z = \pm R \pm (2n + 1) \pi i\]:
\begin{figure}[H]
    \centering
    \incfig{hankel2}
\end{figure}

Let $J(z) = \int_{C} \frac{t^{z-1}}{e^{-t} -1} dt$

The integral has a branch cut on the negative real axis, with branch point at $0$, and poles at $z = 2\pi i n$, $n \in \Z\setminus \{0\} $. The residues at these points are given by $\lim_{z\to 2\pi i n} \frac{(t-2\pi i n)}{e^{-t} - 1} t^{z-1} = \frac{-1}{(2\pi i n)^{1-z}}$ by l'H\^{o}pital's rule. 

So, by our Hankel representation, 
\begin{align*}
	\frac{2\pi i}{\Gamma(1-z)} \zeta(z) &= -2\pi i \sum_{n=1}^{N} (-2\pi i n)^{z-1} - (2\pi i n)^{z-1} \\
	&= 2\pi i (2\pi)^{z-1} \frac{(i)^{z} - (-i)^{z}}{i} \sum_{n=1}^{N} \frac{1}{n^{1-z}} \\
	&\to 2\pi i (2\pi)^{z-1} 2\sin\left( \frac{\pi z}{2} \right) \zeta(1-z)
\end{align*} 

It can be shown that the contributions from the rectangular sides vanish in the limit $R, N \to \infty$.
\end{proof}

It follows easily from the functional equation that $\zeta(-2n) = 0$ for  $n \in \N$. We can see that $\zeta(2n) \neq 0$ because the zeroes of the sin are cancelled by the poles of the Gamma function. 
\zeta(1 + 2n) = \Gamma(-2n) \zeta(-2n) \neq  0, and similarly $\zeta(0) \neq 0$.

\subsubsection*{The Riemann Hypothesis}

The Riemann Hypothesis states that all non-trivial zeroes of the zeta function lie on the critical line $z = \frac{1}{2} + it$.

\subsection{Elliptic Functions}

\begin{defn}
	A \textit{doubly periodic} function $f(z)$ is one that has two periods, $\omega_1$ and $\omega_2$ such that $\frac{\omega_1}{\omega_2} \not\in \R$, with $f(z + \omega_1) = f(z + \omega_2) = f(z)$, and more generally $f(z + m\omega_1 + n\omega_2) = f(z)$ for all $m,n \in \Z$.
\end{defn}

\begin{defn}
	A double-periodic function which is meromorphic is called \textit{elliptic}.
\end{defn}

Assume wlog that $\omega_1 \in \R$. The parallelogram with sides $\omega_1$ and $\omega_2$ is called a cell, and can be extended to form a lattice of periodicity in $\C$. 

Then all zeroes and poles of an Elliptic function correspond to zeroes and poles in any one cell.

\begin{prop}
	\begin{enumerate}
		\item The number of zeroes and poles in one cell is finite. \\
		\item An elliptic function with no poles in a cell is constant.
	\end{enumerate}
\end{prop}

(No proof given)

\subsubsection*{The Weierstrass $\mathcal{P}$-function}

Let  $\omega_{m,n} = m\omega_1 + n\omega_2$, and define
\[
	\mathcal{P}(z) = \frac{1}{z^2}  + \sum_{m,n \in \Z^2\setminus{\{(0,0)\} }} \frac{1}{(z-\omega_{m,n})^2} -\frac{1}{\omega_{m,n}^2}
\] 

It is meromorphic, with infinitely many poles at lattice points.

To show ellipticity, consider $\mathcal{P}(z+\omega_{k,l})$ for given $k,l$, and shift the summation to be centered there. 

\begin{prop}
	The $\mathcal{P}$ function satisfies
	\[
		\left( \mathcal{P}' \right)^2 = 4 \mathcal{P}^3 - g_2 \mathcal{P} - g_3 
	,\] where $g_2 = 60 \sum_{(m,n)\in \Z^2\setminus (0,0)} \frac{1}{\omega_{m,n}^{4}}$, and $g_3 = 140 \sum_{m,m \in \Z^3\setminus (0,0}\frac{1}{\omega_{m,n}^{6}}$ 
\end{prop}

\begin{proof}
	See example sheet 3. Hint: Consider $Q(z) = \mathcal{P}(z) - \frac{1}{z^2}$, and argue that $Q$ is analytic and even in the region of $z=0$. Then, Taylor expand it.
\end{proof}

Rearranging our ODE and integrating, we get
 \[
	 z = \int_{w(z)}^{\infty} \frac{ds}{4s^3 - g_2s - g_3} = \mathcal{P}^{-1}(w) - \alpha
 ,\] where $w = \mathcal{P}(z+\alpha)$. Thus,  $\mathcal{P}$ can be given as the  inverse of an elliptic integral (we call this integral and elliptic integral of the first kind). Note - compare this to the relation
 \[
 \arcsin z = \int_{0}^{z} \frac{ds}{\sqrt{1-s^2}}
 \] 

\begin{eg} (General Elliptic ODE)
	
	Consider $w' = (w-a)(w-b)(w-c)(w-d)$. This is solved by an elliptic integral
	\[
		z + \alpha = \int_{w}^{\infty} \frac{ds}{\left[ (s-a)(s-b)(s-c)(s-d) \right]^{\frac{1}{2}} }
	\] 

	This can be reduced to a more useful form by moving one root to $\infty$, and shifting the remaining roots as follows. Let $t= \frac{1}{u-d}$. Then
	\[
		\frac{du}{\left[ (u-a)(u-b)(u-c)(u-d) \right]^{\frac{1}{2}} } \mapsto \frac{-dt}{t^2 \left[ (\frac{1}{t} - \tilde{a})(\frac{1}{t} - \tilde{b})(\frac{1}{t} - \tilde{c})\frac{1}{t} \right]^{\frac{1}{2}} } = \frac{Adt}{\left[ (t-t_1)(t-t_2)(t-t_3) \right]^{\frac{1}{2}} }
	,\] 
	where A is some constant. Thus, the quartic integrand has been reduced to a cubic with one root moves to $\infty$ (assuming the original d is not \infty). Finally, set $t = s + \gamma$, with $\gamma$ chosen such that  $t_1 + t_2 + t_3$ is moved to 0, and then rescale $s$ such that the leading term has coefficient 4. We then arrive at our previous equation.
\end{eg}

\begin{eg} (Euler's Top)

	Consider
	\begin{align*}
		w_1' &= w_2w_3 \\
		w_2' &= w_3w_1 \\
		w_3' &= w_1w_2
	\end{align*}
	which gives 
	\begin{align*}
		w_2'w_2 - w_3'w_3 = w_1'w_1 - w_3'w_3 = 0
	,\end{align*} and so there exists constants $B, C$ such that $w_3^{2} = w_2^2 + B = w_1^2 + C$
	
	Then we can write
	\[
		(w_3')^2 = (w_3^2 - B)(w_3^2 - C)
	\] which is a special case of the elliptic ODE. 
\end{eg}

\section{Solving Differential Equations by Transform Methods}

\subsection{Solution of ODEs by integral representation}

Our idea is to look at general solutions given by integrals in $\C$. We will motivate this with an example.

\begin{eg} (Airy's Equation)

	\[
		\omega''(x) + x\omega(x) = 0
	\] 
	
	In this course, the convention is that we take $+$, often you will see the Airy equation written with a $-$. Let us first attempt to solve via the Fourier transform.
	\[
		\hat{\omega}(k) = \int_{-\infty}^{\infty} e^{-ikx}\omega(x) dx,
	\] 
	so
	\[
		-k^2 \hat{\omega}(k) + i \hat{\omega}'(k) = 0
	\] 
	Solving and inverting gives us
	\[
		\omega(x) = \frac{A}{2\pi} \int_{-\infty}^{\infty} \exp\left(-\frac{ik^3}{3} + ikx  \right) dk 
	\] 

	There exists a second, linearly independent solution which is not bounded for large $x$ and doesn't admit a Fourier transform. Instead, we consider the equation in $\C$, with $\omega(z)$.

	Let
	 \[
		 w(z) = \int_{\gamma} e^{zt}f(t)dt
	,\] 
	where we will determine $f(t)$ uniquely, and then establish suitable contours $\gamma$.

	Assume  $\frac{\partial f}{\partial z} =0$, then
	\[
		w''(z) = \int_{\gamma} t^2 e^{zt} f(t) dt
	\] 
	Our equation now becomes
	\[
		\int_{\gamma} (t^2 + z) f(t) e^{zt} dt = 0
	\]
	After integrating $\int_{\gamma} zf(t)e^{zt}dt$ by parts, we obtain
	\[
		\left[ e^{zt}f(t) \right]_{\gamma} + \int_{\gamma} e^{zt} \left( t^2f(t) - \frac{df}{dt} dt \right)  
	\] 
	Note that if  $f(t)$ is entire, and $\gamma$ is closed, then $\left[ e^{zt}f(t) \right]_{\gamma} = 0$.

	We now pick $f(t)$ such that $t^2f(t) - \frac{df}{dt} = 0$, and hence
	\[
		f(t) = Ae^{\frac{t^3}{3}}
	\]

	Having found $f$, we can choose $\gamma$ such that $\left[ e^{zt}e^{\frac{t^3}{3}} \right]_{\gamma} = 0$. We choose $\gamma$ which starts/ends at $\infty$ (a closed contour will give a trivial solution $w \equiv 0$). Set $t = |t| e^{i\theta}$. For large $|t|$, we can write  $e^{zt + \frac{t^3}{3}} \sim e^{\frac{t^3}{3}} = e^{\frac{1}{3}|t|^3\cos 3\theta}e^{\frac{i}{3}|t|^3\sin 3\theta}$.

	So, we require $\cos 3\theta < 0$ for this to vanish.

	As such, a conventional choice of contour is as such:

\begin{figure}[ht]
    \centering
    \incfig{airy-contour}
\end{figure}

By Cauchy,
\[
\oint_{\gamma_1 + \gamma_2 + \gamma_3} = 0 
\] 

So only 2 of the contours give linearly independent solutions (no proof of linear independence).

So, we choose any pair of contours.

We deform $\gamma_1$ to the Imaginary axis, getting

\begin{align*}
	 w_1(z) &= C  i\int_{-\infty}^{\infty} e^{izy - i \frac{y^3}{3}}dy \\
		&= C \left[ i \underbrace{\int_{-\infty}^{\infty} \cos\left( zy - \frac{y^3}{3} \right) dy}_{\text{real for real z}} - \underbrace{\int_{-\infty}^{\infty} \sin\left( zy - \frac{y^3}{3} \right) dy}_{\text{real for real z}} \right]  \\
 \end{align*} which is the solution obtained by Fourier transform.

We from here define Airy's function of the 1st kind:
\[
	Ai(z) = \frac{1}{\pi} \int_{0}^{\infty} \cos\left( zy - \frac{y^3}{3} \right) dy
\] 


Now, instead we deform $\gamma_2$ such that it follows the axes as such: 
\[
	\gamma_2 = \{t = iy, y \in (\infty, 0)\} \bigcup \{t = -x, x \in [0, \infty)\} 
\]

Then
\begin{align*}
	w_2(z) = C \left[ i \int_{\infty}^{0} e^{izy - i \frac{y^3}{3}}dy - \int_{0}^{\infty} e^{-zx - \frac{x^3}{3}} dx\right] 
\end{align*} is our second linearly independent solution. We can see that the second integral is unbounded as $z \to  -\infty$.

We write
\[
	Bi(x) = \frac{1}{\pi} \int_{0}^{\infty} \left[ \sin\left( \frac{x^3}{3} - zx \right) - \exp\left(-zx - \frac{x^3}{3} \right)  \right] 
\] to be Airy's function of the second kind (real part of the above with $C = -\frac{1}{\pi}$).
\end{eg}

\subsection{Solving ODE by integral representation: General Method}

For equations of the form
\[
aw'' + bw' + cw =0
\]
Where $w=w(z)$, and $a,b and c$ are low-order polynomials in $z$ (so that we can integrate by parts),set
 \[
	 w(z) = \int_{\gamma} K(z,t)f(t)dt
\]

Substituting back into the ODE, we integrate by parts to eliminate the terms with $z^{n}$, choosing $f(t)$ appropriately to do so. The factor $K(z,t)$ is called a \textit{kernel}. The three following kernels are commonly used:
\begin{align*}
	e^{zt} & \text{(Laplace kernel)} \\
	(z-t)^{\gamma} & \text{(Euler kernel)}\\
	t^{z} & \text{(Mellin kernel)}
\end{align*}

An example of the Euler kernel is given by:
\[
	w(z) = \int_{\gamma} t^{a-c} (a-t)^{c-b-1} (t-z)^{-a} dt
,\] which satisfies the hypergeometric equation
\[
	z(1-z)w'' + [c - (a+b-1)z] w' -abw = 0
\] with constants $a,b,c$, provided that
\[
	\left[ t^{a-c+1} (1-t)^{c-b} (t-z)^{1-a}\right]_{\gamma} = 0  
\] 

The integrand might have branch points, possible at $t = 0, 1, z$, depending on the values of $a, b, c$ and whether the exponents are integers. If there are any branch cuts, then of course $\gamma$ must not cross them (see q6 on ES3).

\subsection{Solving PDEs by Integral Transform}

\begin{defn} (Laplace Transform)

	For functions which have support on semi-intervals, e.g  $f(x) = 0$ for $x < 0$, we define the Laplace transform
	 \[
		 \hat{f}(p) :=  \int_{0}^{\infty} e^{-px}f(x) dx
	,\]  with inverse

	\[
		f(x) =\frac{1}{2\pi i} \int_{c - i\infty}^{c + i\infty} e^{px} \hat{f}(p) dp
	\] 
	where we are integrating over a Bromwich contour such that 
	\[ c > \sup\{x \in \R: \exists y  \in \R, \, f(x + iy) \text{ is singular}\} \]

	Closing the Bromwich contour to the right yields  $f(x) = 0$ for $x < 0$. Closing to the left gives us $f(x)$ for $x \ge 0.$
\end{defn}

\begin{eg} (Waves on a finite string)

	We consider small transverse oscillations, with displacement $y(x)$, satisfying the wave equation

\[
y_{t t} - c^2 y_{x x} = 0
,\] with $y, y_t = 0$ for $t < 0$, $y(0,t) = 0$  $y(l, t) = y_0$ (sudden displacement). 

(An alternative model for this might be a capacitor plate given some charge).

Taking Laplace transforms (as it is an IVP),
\[
	p^2 \hat{y}(x, p) = c^2 \hat{y}_{x x}(x,p)
\] 
And so 
\[
	\hat{y}(x,p) = A(p) \sinh\left( \frac{px}{c} \right) + B(p) \cosh\left( \frac{px}{c} \right) 
\] 
Our boundary conditions give
\begin{align*}
	\hat{y}(0,p) &= 0 \\
	\implies B(p) &\equiv 0
\end{align*}
And also
\[
	y(l,t) = y_0 \implies \hat{y}(l,p) = \int_0^{\infty} y_0 e^{-pt} dt = \frac{y_0}{p}
\]
So  \[
	A(p) \sinh\left( \frac{lp}{c} \right) = \frac{y_0}{p}
\] 

Hence \[
	\hat{y}(x, p) = \frac{y_0}{p} \frac{\sinh\left( \frac{xp}{c} \right) }{\sinh \left( \frac{lp}{c} \right) }
\] 

Then 
\[
	y(x,t) = \frac{1}{2\pi i} \int_{\tilde{c} - i\infty}^{\tilde{c} + i\infty} e^{pt} \frac{y_0}{p} \frac{\sinh \left( \frac{xp}{c} \right) }{\sinh\left( \frac{lp}{c} \right) } dp
\] 
	
Our integrand has simple poles at $p = \frac{m \pi c i}{l}$. As $|p| \to \infty$ with $\Re p >0$, our integrand is approximately $\frac{e^{\frac{xp}{c}}e^{pt}}{pe^{\frac{lp}{c}}} = \frac{1}{p} e^{(x-l+ct)\frac{p}{c}}$.

So if $x - l + ct <0$, we close in the RHP, and so $y(x,t) = 0$ by Cauchy's theorem.

If $-x + l + ct > 0$, we close in the LHP, our radial contributions vanish, and so get that 
\begin{align*}
	y(x,t) = y_0 \sum_{m=-\infty}^{\infty} \res\left( \frac{e^{pt}}{p} \sinh\left( \frac{xp}{c} \right) \frac{1}{\sinh\left( \frac{lp}{c} \right) } ; \frac{m\pi c i}{l}\right)
\end{align*} 

For $m=0$, by l'H\^{o}pital's rule our residue is \[
		\lim_{p\to 0} \frac{\frac{x}{c} \cosh(\frac{xp}{c}) e^{pt} + p\sinh(\frac{xp}{c}) e^{pt}}{\frac{l}{c} \cosh(\frac{lp}{c})} = \frac{x}{l}
	\] 
For $m \neq 0$, our residue is similarly
\begin{align*}
	\frac{\sinh(\frac{im \pi}{c}) \exp(i \frac{m\pi c}{l} t) }{im \pi \cosh(i m \pi)} &= \frac{i \sin(\frac{m\pi x}{l}) \exp(i \frac{m\pi c}{l}t)}{i m \pi \cos(m\pi)} \\
\end{align*}

Hence for $t > \frac{x-l}{c}$,
\[
	y(x,t) = \frac{x}{l}y_0 + y_0 \sum_{m=1}^{\infty}(-1)^{m} \frac{\sin \left( \frac{m \pi x}{l} \right) \cos\left( \frac{m\pi ct}{l} \right)  }{m \pi}
\] 

Note that for $-l + x < ct < l-x$, both our solutions are valid. Thankfully, the Fourier series solution is $0$ here (no proof). So, as we expect, our solution 'switches on' at $t=\frac{l-x}{c}$, so the disturbance propagates from the right at speed c.
\end{eg}

\begin{remark}
	For an alternative inversion method, see handout. By this method, we get
	\[
		y(x,t) = y_0 \sum_{n=0}^{\infty} \Theta(ct + x - (2n+1)l) - \Theta(ct - x - (2n+1)l)
	,\] which is equivalent. We can see that this represents a linear superposition of waves caused by reflections at the two ends of the string. 
\end{remark}

\section{Second-Order ODEs in the Complex Plane}

We start with what is essentially a revision of IA.

Consider 
\[
	w'' + p(z)w' + q(z)w = 0 \tag{1}
,\] where p, q and w are meromorphic on $\C$. 

\subsection{Classification of Singular Points}

\begin{defn}
	The point $z=z_0$ is an \textit{ordinary point} of (1) if $p$ and $q$ are both analytic at $z_0$. Otherwise $z_0$ is a \textit{singular point}.

	If $z_0$ is a singular point, but $(z-z_0)p(z)$ and $(z-z_0)^2q(z)$ are analytic at $z_0$, then $z_0$ is a \textit{regular singular point}. Otherwise, $z_0$ is an irregular singular point.
\end{defn}

For linear ODEs, the singularities of the solutions are independent of the initial conditions - they are fully determined by $p$ and $q$. This does not hold for non-linear ODEs. For example,

\[
	w' + w^2 = 0 \quad \implies \frac{dw}{w^2} = -dz \quad \implies w(z) = (z-z_0)^{-1}
,\] where the singularity at $z_0$ is movable, depending on the constant of integration.

We can extend our definitions to $z=\infty$ by setting $z=\frac{1}{t}$ as follows:

By the chain rule,
\[
	\frac{d^2w}{dt^2} + \left( \frac{2}{t} - \frac{p\left( \frac{1}{t} \right) }{t^2} \right) \frac{dw}{dt} + \frac{q\left( \frac{1}{t} \right) }{t^{4}} w =0
\] 
Hence $t=0$ (so $z=\infty$ ) is an ordinary point if $P(t) := \frac{2}{t} - \frac{p\left( \frac{1}{t} \right) }{t^2}$ is analytic at $t=0$.

So,  \[
	p(z) = \frac{2}{z} + \frac{P\left( \frac{1}{z} \right) }{z^2}
,\] and similarly
\[
	q(z) = \frac{Q\left(\frac{1}{z}\right)}{z^{4}}
\] 
Where $Q(z)$ and  $P(z)$ are analytic at $0$.

Similarly,  $ t=0 (z=\infty)$ is a regular singular point if
\[
	2 - \frac{p\left(\frac{1}{t}\right)}{t}, \quad \frac{q\left(\frac{1}{t}\right)}{t^2}
\] are analytic at $t=0$.

Or equivalently, we can find  $f, g$ analytic at $0$ such that
\[
	p(z) = \frac{2}{z} + \frac{1}{z}f\left( \frac{1}{z} \right), \qquad q(z) = \frac{1}{z^2}g\left( \frac{1}{z} \right) 
\] 

Note that $p$ has at most a simple pole at $\infty$, and $q$ has at most a double pole.

\begin{eg} Legendre's Equation
	\[
		w'' - \frac{2z}{1-z^2} + \frac{n(n+1)}{1-z^2} w =0
	,\] which immediately has regular singular points at $z = \pm 1$

	We now check the behaviour at $\infty$.

	\begin{align*}
		q(z) = \frac{n(n+1)}{1-z^2} = \frac{1}{z^{4}} \frac{n(n+1)z^{4}}{1-z^2} := \frac{1}{z^{4}} g(\frac{1}{z})
	\end{align*}

	$g$ is not analytic at $z=\infty$, so this is not an ordinary point.

	\[
		p(z) = \frac{-2z}{1-z^2} = \frac{2}{z} + \frac{f\left( \frac{1}{z} \right) }{z}
	,\] for $f\left( \frac{1}{z} \right) = -\frac{2}{1-z^2}$, which is analytic at $\infty$.

	Similarly,
	\[
		q(z) = \frac{1}{z^2}g\left( \frac{1}{z} \right), \qquad g\left(\frac{1}{z}\right) := \frac{n(n+1)z^2}{1-z^2}
	,\] which is analytic at $\infty$.

	Hence $z=\infty$ is a regular singular point of Legendre's Equation.
\end{eg}

\begin{remark}
	In many cases, the differential equations can be approximated at infinity. For example, here $\frac{1}{1-z^2} \sim -\frac{1}{z^2}$, which allows as to see clearly that $z=\infty$ is a regular singular point.
\end{remark}

\subsection{Indicial Equations}

Consider a regular singular point at $z=0$, and write
\[
	w(z) = z^{\sigma} \sum_{n=0}^{\infty} a_n z^{n} \tag{2}
\]
Let $p(z) = \sum_{m=-1}^{\infty} p_m z^{m}$, $q(z) = \sum_{m=-2}^{\infty} q_m z^{m}$.

Then our coefficients $p_m, q_m$ determine $\sigma$ and the coefficients $a_n$ (up to constants).
That is,
\[
\sum_{n=0}^{\infty} \left[a_n (n+\sigma)(n+\sigma - 1) z^{n+\sigma -2} + \sum_{m=-1}^{\infty} p_m a_n(n+\sigma) z^{n+m+\sigma - 1} + \sum_{m=-2}^{\infty} q_m a_n z^{n+m+\sigma}\right] = 0
\] 

Then considering our lowest order coefficients of $z$, we get an indicial equation for $\sigma$:
 \[
	 a_0 \left[ \sigma(\sigma-1) + p_{-1}\sigma + q_{-2} \right] = 0
\]
And so assuming $a_0\neq 0$,
\[
	\sigma  =\frac{1 - p_{-1} \pm \sqrt{\left( p_{-1} -1 \right)^2 - 4q_{-2}} }{2}
\] 

And so $w_1(z) = z^{\sigma_1}(a_0 + a_1z + \ldots)$, and $w_2(z) = z^{\sigma_2}(a_0 + a_1z  \ldots) $. As such, in this context $\sigma$ is sometimes referred to as the exponent at $z=0$.

Now, consider a regular singular point at  $z=\infty$.

\begin{align*}
	w &= t^{\sigma} \sum_{n=0}^{\infty}a_n t^{n} = z^{-\sigma} \sum_{n=0}^{\infty} a_n z^{-n} \\
	p(z) &= \frac{2}{z} + \frac{1}{z}f\left(\frac{1}{z}\right)  =\frac{2}{z} + \frac{1}{z} \sum_{n=0}^{\infty} f_n z^{-n} =: \sum_{m=1}^{\infty}p_m z^{-m}\\
	q(z) = \frac{1}{z^2} g\left( \frac{1}{z} \right) =: \sum_{m=2}^{\infty}q_m z^{-m}
\end{align*}

So
\[
	\sum_{n=0}^{\infty} \left[ a_n(-n-\sigma)(-n - \sigma - 1)z^{-n-\sigma-2} + \sum_{m=1}^{\infty} p_m a_n (-n-\sigma)z^{-m-m-\sigma-1} + \sum_{m=2}^{\infty} q_m a_n z^{-n-m-\sigma}\right] =0
\] 
Hence our indicial equation is
\[
	-\sigma(-\sigma-1) - p_1\sigma + q_2 = 0
\] 

\subsection{Solutions Near a Regular Singular Point}

(see handouts also)

Consider a regular singular point at $z=0$. For $|z|\ll 1$, we can our ODE by
\[
w'' + \frac{p_{-1}}{z}w' + \frac{q_{-2}}{z^2}w \approx 0
\] 

The solutions are $w_1 = z^{\sigma_1}$, $w_2 =z^{\sigma_2}$ if $\sigma_1, \sigma_2$ are distinct, and $w_1 = z^{\sigma_1}$ if they are equal.

\begin{thm}
	Let $z=0$ be a regular singular point of
	\[
	w'' + p w' + qw = 0 
	\] 
	Then there are two linearly independent solutions  $w_1, w_2$ such that if
	\begin{enumerate}
		\item $\sigma_1 - \sigma_2 \not\in \Z$: 
			\[
				w_1(z) = z^{\sigma_1} u_1(z), \quad w_2(z) = z^{\sigma_2}u_2(z)
			,\] where $u_1, u_2$ are analytic on some neighbourhood of 0, and $u_i(0) \neq 0$. \\
		\item $\sigma_1 = \sigma_2$:
			\[
				w_1(z) = z^{\sigma_1}u_1(z), \quad w_2(z) = z^{\sigma_2}u_2(z) + w_1(z) \ln z
			,\] $u_i$ as above. \\ 
		\item $\sigma_1 - \sigma_2 \in \Z\setminus \{0\} $ and wlog $\sigma_1 > \sigma_2$ :
			\[
				w_1(z) = z^{\sigma_1}u_1(z), \quad w_2(z) = z^{\sigma_2}u_2(z) + cw_1(z) \ln z
			,\] where $u_i$ as above, and $c$ is a constant that might be zero. 
			
	\end{enumerate}
\end{thm}

\begin{proof}
	We here prove case 1, and leave the other cases to a handout.

	Substituting $w(z) = \sum_{n=0}^{\infty} a_n z^{n+\sigma}$ into our ODE, equating coefficients, and assuming $a_0 \neq 0$, we get

	\begin{align*}
		a_0 F(\sigma) &= 0 \\
		a_n F(n+\sigma) &= - \sum_{k=0}^{\infty} a_k \left( (k+\sigma) p_{n-k-1} + q_{n-k-2} \right) \quad (n > 0) 
	\end{align*}
	where $F(x):= x(x-1) + p_{-1}x + q_{-2} = (x-\sigma_1)(x-\sigma_2)$

	Since $a_0 \neq 0$, $F(\sigma) = 0$ is the indicial equation, and so 
	\[
	\sigma_1 + \sigma_2 = 1 - p_{-1}, \quad \sigma_1\sigma_2 = q_{-2}
	\] 

	If $\sigma_1 - \sigma_2 \not\in \Z$, then we get a recurrence relation for $a_k$ with two linearly independent solutions.
\end{proof}

\begin{eg} Bessel's Equation

	\[
		w'' + \frac{1}{z} w' + \left(1-\frac{\gammma^2}{z^2}\right)w =0
\]
Our non-zero coefficients are $p_-1 = 1, q_0 = 1, q_{-2} = -\gamma^2$. So (ignoring $\gamma = 0$) we obtain (near $z=0$):

\begin{align*}
	a_0F(\sigma) &= a_0(\sigma^2 - \gamma^2) = 0 \\
	a_1 F(\sigma + 1) &= 0 \\
	\vdots \\
	a_nF(\sigma + n) &= -a_{n-2}
\end{align*}
so $\sigma_{1,2} = \pm \gamma$
\end{eg}

\subsection{Fuchsion Equations}

We consider second order ODEs as before with at most three regular singular points.

\subsubsection{No singular points}

\begin{prop}
	There are no ODEs without singular points in $\C_{\infty}$.
\end{prop}

\begin{proof}
	If there are no singular points, then  $p(z)$ is entire on $C_{\infty}$ and is thus constant by Liouville's theorem. But $z = \infty$ is an ordinary point, so $p(z) = \frac{2}{z} + f\left( \frac{1}{z} \right) $, so it is not a constant.
\end{proof}

\subsubsection{One regular singular point}

Wlog we can assuming the singular point is at $z=0$ (as we can move it via M\"{o}bius transforms), and all other points are ordinary.

At  $z=0$, 
\[
	zp(z) = P(z), \quad z^2q(z) = Q(z)
,\] where $P$ and $Q$ are entire on $\C_{\infty}$.

At $z=\infty$,
\[
	p(z) = \frac{2}{z}+\frac{1}{z^2}A\left( \frac{1}{z} \right), \quad q(z) = \frac{1}{z^{4}}B\left( \frac{1}{z} \right)  
,\] where $A$ and $B$ are entire on $C_{\infty}$.

So $P(z) = 2 + \frac{1}{z}A\left( \frac{1}{z} \right) $ is entire, and so $A=0$ by Liouville's Theorem. $Q(z) = \frac{1}{z^2}B\left( \frac{1}{z} \right)$ is also entire, and so also $B = 0$.

Hence our ODE takes the form
\[
	w'' + \frac{2}{z} w' = 0
,\] which has solution 
\[
	w(z) = \alpha + \frac{\beta}{z}
\] for some constants $\alpha, \beta$.

\begin{lemma}
	 A M\"{o}bius transformation $M: z\to t$ will transform an ODE of the form
	 \[
		 w'' + p(z) w' + q(z) w = 0
	 \] into another ODE of the same form. The singular points move according to $z_0 \mapsto M(z_0)$, with exponents unchanged/
\end{lemma}

Proof is not given - consider the generators of scaling, translation and inversion.

\vspace{1em}
Thus, if the singular point is at $z=z_0 \neq \infty$, then we let $t = z-z_0$, and trivially our solution is 
\[
w = \alpha + \frac{\beta}{z-z_0}
\] 

If $z_0 = \infty$, we let $t =\frac{1}{z}$, and so by chain rule,
\[
\frac{d^2w}{dt^2} = 0 \quad\implies w = \alpha + \frac{\beta}{t} = \alpha + \beta z
\] 
\subsubsection{Two regular singular points}

Wlog we can assume that $z=0, 1$ are the singular points, with all other points ordinary.

So
\[
	p(z) = \frac{1+A}{z} + \frac{1+B}{z-1}  + \underbrace{P(z)}_{\text{entire}}
\] 

$z=\infty$ is an ordinary point, so $p(z) = \frac{2}{z} + \mathcal{O}\left( \frac{1}{z^2} \right) $ as $z\to \infty$.

Hence  \[
\frac{1+A}{z} + \frac{1+B}{z-1} \to \frac{2}{z}
,\] and so $A+B = 0$.

As  $p(z) \to 0$ at infinity, $P(z) = 0$ by Liouville's theorem.

Hence 
\[
	p(z) = \frac{1+A}{z} + \frac{1-A}{z-1}
\] 


Now, $q(z) = \frac{Cz+D}{z^2} + \frac{Ez + F}{(z-1)^2} + Q_2(z)$, with $Q_2$ entire. So
\[
	q(z) =: \frac{Q_1(z)}{z^2(z-1)^2} + Q_2(z)
,\] for some polynomial $Q_1$ of degree at most $3$.

As $z=\infty$ is an ordinary point, $z^{4}q(z)$ is bounded at infinity, and so $Q_2$ = 0.

Further,
\[
	\frac{z^{4}Q_1(z)}{z^2(z-1)^2} \to Q_1(z) \text{ as } z\to \infty
,\] so $Q_1(z) = Q$ constant. 

Hence
\[
	w'' + \left( \frac{1+A}{z} + \frac{1-A}{z-1} \right)w' + \frac{Q}{z^2(1-z)^2} w = 0
,\] for constant A, where $z = 0, 1$ are our regular singular points.

Consider exponents in the vicinity of $z = 0$. Then we can approximate
\[
w'' + \frac{1+A}{z}w' + \frac{Q}{z^2}w \sim 0
\] 
and so get indicial equation
\[
\sigma^2 + A \sigma + Q = 0
\] 

Similarly, at $z=1$ we get
\[
	w'' + \frac{1-A}{z-1}w + \frac{Q}{(z-1)^2}w \sim 0 \quad \implies \sigma^2 - A\sigma + Q =0
\] 

We can use M\"{o}bius transforms to move the singular points. In particular, we can use $t=\frac{1}{2}$ to map $0 \mapsto \infty, 1 \mapsto 1$.

So \[
	t^{4} w_{t t} + \left[ 2t^3 - t^2\left( t(1+A) + \frac{t(a-A)}{1-t} \right)  \right]w_t + t^{4}\frac{Q}{(t-1)^2} w = 0
\] 
And we thus obtain
\[
	w'' + \frac{1-A}{t-1}w' + \frac{Q}{(t-1)^2}w = 0
\] 

So our indicial equation at $t=1$ is given by
\[
\sigma^2 - A\sigma + Q = 0
,\] the same as before at $z=1$, and at $t=\infty$ we get
\[
\sigma^2 + A\sigma + Q = 0
,\] the same as before at $z=0$.

Note that solutions near  $z=0$ take the form $z^{\sigma_1} u_1(z) + z^{\sigma_2} u_2(z)$, where $U_i$ is analytic. The solutions at $t=\infty$ take the form $w(t) = t^{-\sigma_1}u_1\left(\frac{1}{t}\right) + t^{-\sigma_2} u_2\left( \frac{1}{t} \right) $

\subsubsection{Three Regular Singular Points - The Papperitz Equation (Riemann's P-Equation)}

(also see handout)

We show that there are $8$ parameters in the P-equation: 3 from positions of the singular points, 6 for exponents (2 per singular point), but -1 from a constraint on the exponents as they must add up to 1.

Suppose the three regular singular points are at $z= a, b, c$ with all other points regular. Then wlog we can write $p(z)$ in the form
\[
	p(z) = \frac{1-\alpha - \alpha'}{z-\alpha} + \frac{1-\beta - \beta'}{z-\beta} + \frac{1-\gamma - \gamma'}{z-c} + P(z)
,\] where $P$ is entire.

As $z=\infty$ is an ordinary point, then $p(z)$ is bounded at $\infty$, and so by Liouville's theorem $P(z)$ is constant (wlog 0).

Further,
\[
	zp(z) \to 2 \text{ as } z\to \infty \quad \implies (1-\alpha - \alpha') + (1-\beta - \beta') + (1-\gamma - \gamma') = 2
,\]
so
\[
\alpha + \alpha' + \beta + \beta' + \gamma + \gamma' =1
\]

Next, wlog
\begin{align*}
	q(z) &= \frac{k_{\alpha} z - k_{\alpha}'}{(z-\alpha)^2} + \frac{k_{\beta} z - k_{\beta}'}{(z-\beta)^2} + \frac{k_{\gamma}z + k_{\gamma}'}{(z-\gamma)^2} + Q_2(z) \\
	=: \frac{Q_1(z)}{(z-a)^2(z-b)^2(z-c)^2} + Q_2(z)
\end{align*}
	where $Q_2$ is entire, and $Q_1$ is a polynomial of degree at most $5$.

	As  $z=\infty$ is an ordinary point, $z^{4}q(z)$ is bounded as $z\to \infty$, and so by Liouville's theorem,  $Q_2$ is constant (wlog 0), and $Q_1$ is at most quadratic.

	Hence we can write
	\[
		q(z) = \frac{1}{(z-a)(z-b)(z-c)}\left( \frac{q_a}{z-a} + \frac{q_b}{z-b} + \frac{q_c}{z-c} \right) 
	\] 

	We can now specify $\alpha, \alpha', \beta, \beta', \gammma, \gamma'$ by writing
	\begin{align*}
		q_a &= \alpha\alpha' (a-b)(a-c) \\
		q_b &= \beta \beta' (b-a)(b-c)\\
		q_c &= \gamma \gamma' (c-a)(c-b)
	\end{align*}
	and so we can fix our constants under  $\alpha + \alpha' + \beta + \beta' + \gamma + \gamma'$ =1, giving us our 8 degrees of freedom.

	This gives the Papperitz equation:

	\begin{align*}
		w'' + &\left( \frac{1-\alpha - \alpha'}{z-a} + \frac{1-\beta - \beta'}{z-b} + \frac{1- \gamma - \gamma'}{z-c} \right) w' \\ - &\frac{(b-c)(c-a)(a-b)}{(z-a)(z-b)(z-c)} \left[ \frac{\alpha\alpha'}{(z-a)(b-c)} + \frac{\beta\beta'}{(z-b)(c-a)} + \frac{\gamma\gamma'}{(z-c)(a-b)} \right] w = 0
	\end{align*}

	Near $z=a$, the Papperitz equation can be approximated as
	\[
		w'' + \frac{1-\alpha - \alpha'}{z-a}w' + \frac{\alpha\alpha'}{(z-a)^2}w \sim 0
	,\] so our indicial equation is
	\[
		\sigma^2 + (\alpha + \alpha')\sigma + \alpha\alpha' = 0
	,\] and so $\alpha $ and$ \alpha'$ are the exponents are $z=a$, and similarly at $b$ and $c$. 

	We write
	\[
		P \begin{Bmatrix} a & b & c & \\
				\alpha & \beta & \gamma & z \\
				\alpha' & \beta' & \gamma' &
		\end{Bmatrix} 
	\] for the $2d$ vector space of solutions of the P-equation. This is known as the Papperitz (P) - symbol.

	It is a common abuse of notation to write $w(z) = P \begin{Bmatrix} \ldots \end{Bmatrix} $ to mean that $w$ solves the P equation.

\subsection{The Hypergeometric Equation}

A M\"{o}bius transform acts on a P-symbol as follows: 
 \begin{align*}
	 (a,b,c,z) &\to (a', b', c', z') \\
	 P \begin{Bmatrix} a & b & c & \\
                                \alpha & \beta & \gamma & z \\
				\alpha' & \beta' & \gamma' &
			\end{Bmatrix} & \mapsto P \begin{Bmatrix} a' & b' & c' & \\
                                \alpha & \beta & \gamma & z \\
				\alpha' & \beta' & \gamma' &
			\end{Bmatrix}
\end{align*}

We also need to transform P-symbol by exponent shifting.

\begin{prop}
	\[
		\left( \frac{z-a}{z-b} \right)^{\sigma} \left( \frac{z-b}{z-c} \right)^{\delta} P \begin{Bmatrix} a & b & c & \\
                                \alpha & \beta & \gamma & z \\
				\alpha' & \beta' & \gamma' &
			\end{Bmatrix}
			= P \begin{Bmatrix} a & b & c & \\
                                \alpha + \sigma & \beta - \sigma + \delta & \gamma - \delta& z \\
				\alpha' + \sigma & \beta - \sigma + \delta & \gamma - \delta &
			\end{Bmatrix}
	\] 

	And our solution 
	\[
		w(z) \mapsto \left(\frac{z-a}{z-b}\right)^{\sigma} \left( \frac{z-b}{z-c} \right) ^{\delta} w(z)
	\]

\end{prop}

\begin{proof} 
	We prove the case $\delta = 0$, but the proof is easily extended.

	Let us prove the equivalent 
	\[
		\left( \frac{z-a}{z-b} \right)^{\sigma} P \begin{Bmatrix} a & b & c & \\
                                \alpha - \sigma & \beta+\sigma & \gamma & z \\
				\alpha' -\sigma & \beta + \sigma & \gamma&
			\end{Bmatrix}
			= P \begin{Bmatrix} a & b & c & \\
                                \alpha & \beta & \gamma & z \\
				\alpha' & \beta' & \gamma' &
			\end{Bmatrix}
	\] 

	We assume that $w(z)$ is a solution of the RHS, and want to show that $w_1(z) = \left( \frac{z-a}{z-b} \right)^{-\sigma} w(z) $ is a solution to the LHS.

Near $z=a$, 
 \[
	 w(z) = \sum_{n=0}^{\infty} a_n \left( z-a \right)^{n+\alpha}
,\]
so
\begin{align*}
	w_1(z) &= \left( z -a \right)^{\alpha - \sigma} \left( z-\beta \right)^{\sigma} \sum_{n=0}^{\infty} a_n (z-a)^{n} \\
	&= (z-a)^{\alpha - \sigma} \sum_{n=0}^{\infty} c_n (z-a)^{n}
\end{align*} as $(z-b)^{\sigma}$ is analytic at $z=a$.

So  $\alpha$ is shifted to $\alpha - \sigma$, and the result follows.
\end{proof}

Note: If multiply  by$(-b)^{\sigma}$ and take when $b \mapsto \infty$, 

\[
	(z-a)^{\sigma} P \begin{Bmatrix} a & \infty & c & \\
                                \alpha & \beta & \gamma & z \\
				\alpha' & \beta' & \gamma' &
			\end{Bmatrix} = P \begin{Bmatrix} a & \infty & c & \\
                                \alpha + \sigma  & \beta - \sigma & \gamma & z \\
				\alpha' + \sigma & \beta' - \sigma & \gamma' &
			\end{Bmatrix}
\] 


To obtain the Hypergeometric equation, we perform the following operations.
\begin{enumerate}
	\item Map $(a,b,c) \mapsto (0, 1, \infty)$ by M\"{o}bius transform \\
	\item Shift exponents so $\alpha = \beta = 0$ \\
	\item Relabel  $\gamma = A$, $\gamma' = B$,  $\alpha' = 1-C$, then  $\beta' = C - A - B$
\end{enumerate}

So the P-symbol becomes
\[
P \begin{Bmatrix} 0 & 1 & \infty & \\
                                0 & 0 & A & z \\
				1-C & C - A - B & B &
			\end{Bmatrix}
,\]

which corresponds to the hypergeometric equation
\[
	w'' + \left( \frac{C}{z} + \frac{1 + A + B - C}{z-1} \right) w' + \frac{AB}{z(z-1)}w = 0 \tag{\dagger}
\] with regular singular points $0, 1, \infty$. Note that the hypergeometric equation is generally written with lower case letters, not to be confused with our original singular points.

Now, one of the exponents is $0$, so there is a solution that is analytic at $z=0$ with $w(0)=1$. This is known as the hypergeometric function  $F(a, b; c, z) = F(b, a; c, z)$

\begin{prop}
	\[
		F(a, b; c, z) = \sum_{n=0}^{\infty} \frac{(a)_{n} (b)_{n}}{(c)_{n}} \frac{z^{n}}{n!}
	,\] where $(x)_n = x(x+1)\ldots(x+n-1)$, $(x)_0 = 1$ is the \textit{Pochhammer symbol}.
	The series is convergent in $|z| <1$. The singular point at $z=1$ prohibits the series from converging further.
\end{prop}

\begin{proof}
	Since the solution $w(z)$ is analytic, it can be written as a Taylor series
	\[
		w(z) = \sum_{n=0}^{\infty} a_n z^{n}
	\] 
	substituting this into $(\dagger)$ and multiplying by $z-1$, we get
	\begin{align*}
		n(n-1)a_n z^{n-2} + &(n+1)na_{n+1}z^{n-1} + cn a_n z^{n-2} + c(n+1) a_{n+1}z^{n-1} \\
									    &+ (1+a+b-c)(na_n z^{n-1} + (n+1)a_{n+1}z^{n}) + ab(a_nz^{n-1} + a_{n+1}z^{n}) = 0
	\end{align*} 

	The coefficients of $z^{n-1}$ give
	\[
		n(n-1)a_n + (n_1)n a_{n+1} + cn a_n - c(n+1)a_{n+1} + (1+a+b-c)na_n + aba_n = 0
	\] 
	and thus 
	\[
		a_n (n^2 + an + bn + ab) = a_{n+1}(n+1)(c+n)
	\]
	Hence,
	\[
		a_{n+1} = \frac{(a+n)(b+n)}{(c+n)} \frac{1}{n+1} a_n
	,\] which gives the claimed result 
\end{proof}

\begin{remark}
	Many special functions are special cases of the Hypergeometric function:
	\begin{align*}
		(1-z)^{n} &= F(-n, 1; 1, z)\\
		\log(1-z) &= zF(1, 1; 2, z) \\
		e^{z} &= \lim_{b\to 0} F(1, b; 1, \frac{z}{b})
	\end{align*}
\end{remark}

\begin{prop}
	The hypergeometric function has integral representation
	\[
		F(a, b; c, z) = \frac{\Gamma(c)}{\Gamma(b)\Gamma(c-b)} \int_{0}^{1} t^{b-1} (1-t)^{c-b-1}(1-zt)^{-1}dt
	\] 
	for $\Re c > \Re b > 0$ and  $|z| < 1$ so that the integral converges at branch points $0, 1, \frac{1}{z}$.
\end{prop}

\begin{proof}
	See example sheet 4.
\end{proof}


\subsubsection{Second Solution to the Hypergeometric Equation}

Near $ z=0$, there is a solution with exponent $1-c$. It can be expressed in terms of the Hypergeometric function. It has the form  $w(z) = z^{1-c} g(z)$, where $g$ is analytic at $z=0$ and $g(0) = 1$.

We have 
\[
	w(z) = P \begin{Bmatrix} 0 & 1 & \infty & \\
		0 & 0 & a & z \\
		1-c & c-a-b & b & 
	\end{Bmatrix} 
,\] and so by shifting
\[
	g(z) = P \begin{Bmatrix} 0 & 1 & \infty & \\
                c-1 & 0 & a+c+1 & z \\
                0 & c-a-b & b-c+1 & 
        \end{Bmatrix} \equiv P \begin{Bmatrix} 0 & 1 & \infty & \\
                0 & 0 & a-c+1 & z \\
                c-1 & c-a-b & b-c+1 & 
        \end{Bmatrix}
\] as the order of our exponents does not matter.

We let $c' = 2-c$, $a' = a +c - a$,  $b' = b-c+1$. Then
\[
	g(z) = P \begin{Bmatrix} 0 & 1 & \infty & \\
                0 & 0 & a' & z \\
                1-c' & c'-a'-b' & b' & 
        \end{Bmatrix}
\] 

Hence 
 \[
	 w(z) = z^{1-c} F(a-c+1, b-c+1,; 2-c, 2)
\] is the second solution at $z=0$.

\begin{note}
	This works for $c \not\in \Z$.
\end{note}

\subsubsection{Solutions near $z=\infty$ }

The two principal branches at $z=\infty$ of a hypergeometric P-function can be written in terms of hypergeometric functions as follows. Note first that the branches are of the form
\[
	P_a(z) = z^{-a} g_a(z) \qquad \text{and} \qquad P_b(z) = z^{-b} g_b(z)
\] where $g_a(t^{-1})$ and $g_b(t^{-1})$ are analytic at $t=0$.

Now, $P_a(z)$ is a branch of the hypergeometric P-function
\[
P\begin{Bmatrix} 0 & \infty & 1 & \\
                0 & a &  & z \\
                1-c & b & c-a-b & 
        \end{Bmatrix}
\] 

So by exponent shifting, $g_a(z)$ is a branch of
\begin{align*}
	P&\begin{Bmatrix} 0 & \infty & 1 & \\
                a & 0 & 0 & z \\
                1-c+a & b-a & c-a-b & 
        \end{Bmatrix} \\
	&= P \begin{Bmatrix} \infty & 0 & 1 & \\
                a & 0 &  & z^{-1} \\
                1-c+a & b-a & c-a-b & 
	\end{Bmatrix} \text{ by M\"{o}bius transform}\\
	&= P \begin{Bmatrix} 0 & \infty & 1 & \\
                0 & a & 0 & z^{-1} \\
                b-a & 1-c+a & c-a-b & 
        \end{Bmatrix} \text{ reordering columns}\\
	&\equiv P\begin{Bmatrix} 0 & \infty & 1 & \\
                0 & a' & 0 & z \\
                1-c' & b' & c'-a'-b' & 
        \end{Bmatrix}
\end{align*} where $c' = 1+a-b$,  $b' = 1-c+a$, and  $a' = a$

Now, $g_a(z)$ is analytic at $z^{-1} = 0$ and $g(\infty) = 1$, so $g_a(z)$ must e the principle branch of the above P-function corresponding to the exponent 0 at the point $z^{-1} = 0$, which by definition is a hypergeometric function.

Thus
\[
	w(z) = z^{-a} F(a, 1-a+c; 1+a-b, z^{-1})
\] 

The other branch is obtained from this by interchanging $a$ and $b$. Note that since there are only two linearly independent branches at each point, we can express the analytic continuation of $F(a, b; c,z)$ to large $z$ in the form
\[
	F(a, b; c, z) = A z^{-a}F(a, 1-a+c; 1+a-b, z^{-1}) + B z^{-b} F(b, 1-b+c; 1+b-a, z^{-1})
,\] where $A$ and $B$ are constants which can be found using, for example, integral representations of the hypergeometric function. 

\subsection{Monodromy - the need for a logarithmic term}

We briefly revisit our general linear second order ODE
\[
	w'' + p(z)w' + q(z)w = 0 
\] 

For a regular singular point at $z=0$, there exist two linearly independent solutions such that if $\sigma_1 = \sigma_2$, then $w_1(z) = z^{\sigma} u_1(z)$, and $w_2(z) = w_1(z) \log z$.

We now justify why the log term arises.

Consider $\mathcal{D} = \{z: 0 < |z| < R\} $ to be the largest punctured disk with no other singularities. Let $z_0 \in \mathcal{D}$. Then $z_0$ is an ordinary point, so there exists an open disk $\mathcal{D}_0 \subset \mathcal{D}$ which has analytic solutions, wlog $w_1(z) w_2(z)$ which form a Vieta space of dimension 2.

Let $C = \{|z| = |z_0|\} $. We perform analytic continuation using a sequence of disks along $C$ back to $\mathcal{D}_0$. Let $\hat{w}_{1}(z) = w_1\left( e^{2\pi i }z \right) $, $\hat{w}_2(z) = w_2\left( e^{2\pi i } z \right) $ to be the result of analytic continuation back into $\mathcal{D}_0$.

Then we can find a non-singular matrix  $M$ such that
\[
\begin{pmatrix} \hat{w}_1 \\ \hat{w}_2 \end{pmatrix} = M \begin{pmatrix} w_1 \\ w_2 \end{pmatrix} 
\] 

This is known as the Monodromy matrix.

M has two possible Jordan normal forms:
\[
	\begin{pmatrix} e^{2\pi i \sigma} & 0 \\ 0 & e^{2\pi i \sigma} \end{pmatrix} \qquad \text{or} \qquad \begin{pmatrix} e^{2\pi i \sigma} & 0 \\ 1 & e^{2\pi i \sigma} \end{pmatrix} 
\] 

In both cases, $w_1\left(e^{2\pi i} z\right) = \left(e^{2\pi}z\right)^{-\sigma} w_1(z)$. Letting 

In the second case, we have
\[
	w_2\left( e^{2\pi i }z \right) = w_1(z) + e^{2\pi i \sigma} w_2(z)
\]
We let $f(z) = z^{-\sigma} w_2(z) - \frac{e^{-2\pi i \sigma}z^{-\sigma} \log z}{2\pi i} w_1(z)$. Then under the analytic continuation, 
\[
	f\left( e^{2\pi i} z \right) = f(z)
\] 
Now, $f(z)$ is 
\end{document}
